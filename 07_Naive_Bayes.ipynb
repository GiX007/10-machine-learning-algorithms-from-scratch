{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1U83+s0x3tBi4wrqfWauJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX7000/10-machine-learning-algorithms-from-scratch/blob/main/07_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation of a Naive Bayes classifier\n",
        "\n",
        "In this notebook, a quick and simple implementation of a [Naive Bayes](https://www.youtube.com/watch?v=CPqOCI0ahss) algorithm is presented. The Naive Bayes classifier is a probabilistic classifier based on applying [Bayes' theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) with strong(naive) independence assumptions between the features."
      ],
      "metadata": {
        "id": "IzpEiD98W-4k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dd_0GUuBOaOK"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Create a dataset and split it to train and test sets."
      ],
      "metadata": {
        "id": "jcqMa_oJm3Ls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a classification dataset\n",
        "X, y = datasets.make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=123)\n",
        "\n",
        "# split iiit to train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# let's see some things about the data\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
        "print(X_train.dtype, X_test.dtype)\n",
        "print(X_train[5])\n",
        "print(y_train[5])\n",
        "print(np.unique(y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX5JHJulg9EU",
        "outputId": "1554bab4-a955-49c0-afec-c9fb669bfd8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 10) (800,) (200, 10) (200,)\n",
            "float64 float64\n",
            "[-0.14670394  0.68624262 -0.59005397  0.36530023 -0.82320836  0.12463487\n",
            " -0.69878555 -0.73534754 -0.69333204 -1.25232507]\n",
            "0\n",
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a Naive Bayes model."
      ],
      "metadata": {
        "id": "EFVRFDwRg9uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayes:\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self._classes = np.unique(y)\n",
        "        n_classes = len(self._classes)\n",
        "\n",
        "        # calculate mean, var, and prior for each class\n",
        "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "        self._priors = np.zeros(n_classes, dtype=np.float64)\n",
        "\n",
        "        for idx, c in enumerate(self._classes):\n",
        "            X_c = X[y == c]\n",
        "            self._mean[idx, :] = X_c.mean(axis=0)\n",
        "            self._var[idx, :] = X_c.var(axis=0)\n",
        "            self._priors[idx] = X_c.shape[0] / float(n_samples) # num of samples per class / total number of samples\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        posteriors = []\n",
        "\n",
        "        # calculate posterior probability for each class(prior probs + class cond probs)\n",
        "        for idx, c in enumerate(self._classes):\n",
        "            prior = np.log(self._priors[idx])\n",
        "            posterior = np.sum(np.log(self._pdf(idx, x)))\n",
        "            posterior = posterior + prior\n",
        "            posteriors.append(posterior)\n",
        "\n",
        "        # return class with the highest posterior\n",
        "        return self._classes[np.argmax(posteriors)]\n",
        "\n",
        "    # probability density function to calculate class conditional probs like P( x(i) | y )\n",
        "    def _pdf(self, class_idx, x):\n",
        "        mean = self._mean[class_idx]\n",
        "        var = self._var[class_idx]\n",
        "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
        "        denominator = np.sqrt(2 * np.pi * var)\n",
        "        return numerator / denominator"
      ],
      "metadata": {
        "id": "vo0-_82TD-_o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train, predict and evaluate the model."
      ],
      "metadata": {
        "id": "0VJQOsddoqpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create ana instance of our classifier\n",
        "clf_naive_bayes = NaiveBayes()\n",
        "\n",
        "# train the classifier\n",
        "clf_naive_bayes.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Agrbr3CFg834"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on test set\n",
        "predictions = clf_naive_bayes.predict(X_test)\n",
        "\n",
        "# Print the predictions and the actual labels\n",
        "print(\"Predictions:\", np.array(predictions))\n",
        "print(\"Actual Labels:\", y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjEvZFZ1mCwm",
        "outputId": "49772062-b167-4ce4-fba5-0a9fef5840f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 0\n",
            " 1 0 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0\n",
            " 1 1 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1]\n",
            "Actual Labels: [0 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1\n",
            " 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0\n",
            " 1 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            " 0 0 0 1 1 0 1 1 1 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1 0\n",
            " 1 1 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0\n",
            " 0 1 1 0 1 0 1 1 1 0 1 0 0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use how good our model is."
      ],
      "metadata": {
        "id": "TvLyFCJhrl25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy function\n",
        "def accuracy(y_true, y_pred):\n",
        "  return np.sum(y_true == y_pred) / len(y_true)\n",
        "\n",
        "print(accuracy(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEmODCaZmCtp",
        "outputId": "7082638a-3641-446a-9002-5d20671ac1d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a very high score of accuracy of 94.5%.\n",
        "Let's compare it now to the one of scikit-learn library."
      ],
      "metadata": {
        "id": "Nt9tHCp-62s6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Compare with the Naive Bayes classifier from scikit-learn library."
      ],
      "metadata": {
        "id": "7QrFGdlqmOX_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see now, what results a [Gaussian Naive Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html) from scikit-learn library gives us."
      ],
      "metadata": {
        "id": "Al8x6nk-uaHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's compare now with the accuracy that sklearn gives us\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "clf_sklearn = GaussianNB()\n",
        "clf_sklearn.fit(X_train, y_train)\n",
        "sklearn_predictions = clf_sklearn.predict(X_test)"
      ],
      "metadata": {
        "id": "wsDt0S2EmCqx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check the accuracy now\n",
        "print(accuracy(y_test, sklearn_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYMFqAQ9yvJ1",
        "outputId": "58d4a63f-ca70-427d-97dd-aa02e2488f77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got exactly the same high score of accuracy like our custom Naive Bayes classifier gave us. Another great tutorial is [here](https://machinelearningmastery.com/classification-as-conditional-probability-and-the-naive-bayes-algorithm/)."
      ],
      "metadata": {
        "id": "oIFMHeDDzmCo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOghK0QcMuCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}